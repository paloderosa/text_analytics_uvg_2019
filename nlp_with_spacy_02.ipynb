{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción a spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.es import Spanish\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el centro de spacy se encuentra el procesador de lenguaje natural, que llamamos `nlp`. Instanciamos un procesador de la siguiente manera. Este procesador contiene reglas específicas de tokenización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Spanish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se procesa a un texto con el `nlp`, spacy crea un documento `Doc`. El documento permite acceder al texto de una manera estructurada. Este `Doc` ademàs es un iterador de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('¡Hola mundo!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡\n",
      "Hola\n",
      "mundo\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El objeto `Token`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetos `Token` representan a los tokens en el documento, por ejemplo, una palabra o un caracter de puntuación. Para obtener un token específico, lo indexamos en el `doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = doc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetos `Tokens` también tienen varios atributos que nos permiten acceder a más información sobre los tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola\n"
     ]
    }
   ],
   "source": [
    "print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El objeto `Span`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un objeto `Span` es una sección de un documento que consiste de uno o más tokens. Es sólo una vista de un `Doc` y no contiene datos el mismo. Para crear un `Span`, se usa la notación de Python para seleccionar una sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = doc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola mundo\n"
     ]
    }
   ],
   "source": [
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributos léxicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos de los atributos de los `Token`s son los siguientes. `i` es el índice del token dentro del texto. `text` devuelve el texto del token, `is_alpha`, `is_punct` y `like_num` devuelven valores booleanos indicando si el token consiste de caracteres alfanuméricos, puntuación o si _parece_ un número. Estos son atributos léxicos, porque dependen de la palabra misma y no de su contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Cuesta $10.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índice:      [0, 1, 2, 3]\n",
      "Texto:      ['Cuesta', '$', '10', '.']\n",
      "is_alpha:       [True, False, False, False]\n",
      "is_punct:       [False, False, False, True]\n",
      "like_num:       [False, False, True, False]\n"
     ]
    }
   ],
   "source": [
    "print('Índice:     ', [token.i for token in doc])\n",
    "print('Texto:     ', [token.text for token in doc])\n",
    "print('is_alpha:      ', [token.is_alpha for token in doc])\n",
    "print('is_punct:      ', [token.is_punct for token in doc])\n",
    "print('like_num:      ', [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos estadísticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas de las cosas más interesantes que se pueden analizar son específicas a un contexto. Por ejemplo, se puede analizar si una palabra es un verbo o si un `span` de texto es el nombre de una persona.\n",
    "\n",
    "Los modelos estadísticos le permiten a spaCy hacer predicciones en contexto. Estas predicciones son etiquetas de **part-of-speech**, **dependencias sintácticas** y **entidades nombradas**. Estos modelos están entrenados en grandes conjuntos de datos etiquetados y pueden mejorarse con más ejemplos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spacy provee de modelos pre-entrenados que se pueden descargar. Por ejemplo,\n",
    "\n",
    "`$ python -m spacy download es_core_news_md`\n",
    "\n",
    "para un modelo en español entrenado sobre texto de noticias.\n",
    "\n",
    "Después se carga el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciendo dependencias sintácticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usemos al modelo para hacer predicciones. En este ejemplo, vamos a usar spacy y el modelo para predecir etiquetas de **part-of-speech**, los tipos de palabras según su contexto. Una vez que cargamos el modelo, procesamos un texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Ella se comió la pizza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada token en el documento, imprimimos el texto y el atributo `pos_`, el **part-of-speech** que se predice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ella PRON\n",
      "se PRON\n",
      "comió VERB\n",
      "la DET\n",
      "pizza NOUN\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En spacy, los atributos que terminan con un `_` devuelven texto, mientras que atributos sin `_` devuelven ids. Aquí, el modelo correctamente predijo que *comió* es un verbo y que *pizza* es un sustantivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de las etiquetas POS, podemos también predecir como se relacionan las palabras. Por ejemplo, si una palabra es el objeto o el objeto en una oración. El atributo `head` devuelve la equiteta del *padre* sintáctico, el token *padre* al que esta palabra está unida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ella PRON nsubj comió\n",
      "se PRON obj comió\n",
      "comió VERB ROOT comió\n",
      "la DET det pizza\n",
      "pizza NOUN obj comió\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"es\" id=\"3017db96bd8c4f808ae0e4cf3347eba3-0\" class=\"displacy\" width=\"500\" height=\"227.0\" direction=\"ltr\" style=\"max-width: none; height: 227.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Ella</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">se</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">comió</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">la</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">pizza</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3017db96bd8c4f808ae0e4cf3347eba3-0-0\" stroke-width=\"2px\" d=\"M70,92.0 C70,2.0 230.0,2.0 230.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3017db96bd8c4f808ae0e4cf3347eba3-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,94.0 L62,82.0 78,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3017db96bd8c4f808ae0e4cf3347eba3-0-1\" stroke-width=\"2px\" d=\"M160,92.0 C160,47.0 225.0,47.0 225.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3017db96bd8c4f808ae0e4cf3347eba3-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,94.0 L152,82.0 168,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3017db96bd8c4f808ae0e4cf3347eba3-0-2\" stroke-width=\"2px\" d=\"M340,92.0 C340,47.0 405.0,47.0 405.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3017db96bd8c4f808ae0e4cf3347eba3-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,94.0 L332,82.0 348,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3017db96bd8c4f808ae0e4cf3347eba3-0-3\" stroke-width=\"2px\" d=\"M250,92.0 C250,2.0 410.0,2.0 410.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3017db96bd8c4f808ae0e4cf3347eba3-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M410.0,94.0 L418.0,82.0 402.0,82.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas etiquetas\n",
    "\n",
    "| Etiqueta | Descripción | Ejemplo |\n",
    "|----------|-------------|---------|\n",
    "|**nsubj** | sujeto nominal | Ella |\n",
    "|**dobj**  | objeto directo | pizza|\n",
    "|**det**   | determinador (artículo) | la |\n",
    "\n",
    "La lista completa está en https://spacy.io/api/annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciendo entidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las entidades son objetos del mundo real a las que se les asigna un nombre, por ejemplo, una persona, una organización o un país. La propiedad `doc.ents` permite acceder a las entidades predichas por el modelo. Devuelve un iterador de objetos `Span`, de modo que podemos escribir el texto y la etiqueda del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Apple está buscando comprar una startup del Reino Unido por $1000 millones.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Reino Unido LOC\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener deficiones de las etiquetas más comunes, puedes usar la función de ayuda `spacy.explain`. Por ejemplo, **GPE** para una entidad geopolítica no es muy intuitivo, pero `spacy.explain` puede decirte que se refiere a países, ciudades o estados.\n",
    "\n",
    "Esta función igual incluye a etiquetas POS y etiquetas de dependencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('GPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun, proper singular'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct object'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('dobj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coincidencias basadas en reglas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparadas con las expresiones regulares, el `matcher` funciona con objetos `Doc` y `Token` en lugar de con `string`s.\n",
    "\n",
    "Es más flexible: no solo puedes buscar atributos de texto sino también otros atributos de léxico. Puedes incluso definir reglas que usen las predicciones de los modelos, por ejemplo, buscar una palabra solo si es un verbo y no un adjetivo.\n",
    "\n",
    "Los patrones de coincidencia son listas de diccionarios. Cada diccionario describe a un token. Las `keys` son los nombres de los atributos del token, asociados a sus valores esperados.\n",
    "\n",
    "En este ejemplo, buscamos los dos tokens con texto \"iPhone\" y \"X\".\n",
    "\n",
    "`[{'TEXT': 'iPhone'}, {'TEXT': 'X'}]`\n",
    "\n",
    "Podemos buscar otros atributos de tokens. Buscamos dos tokens que en minúsculas sean \"iphone\" y \"x\".\n",
    "\n",
    "`[{'LOWER': 'iphone'}, {'LOWER': 'x'}]`\n",
    "\n",
    "Podemos incluso escribir patrones usando atributos predichos por el modelo. Aquí, buscamos tokens con el lemma \"comprar\", además de un sustantivo. Esto detectaría \"compramos leche\", por ejemplo.\n",
    "\n",
    "`[{'LEMMA': 'comprar'}, {'POS': 'NOUN'}]`\n",
    "\n",
    "Para usar el `matcher`, primero lo importamos desde `spacy.matcher`. El modelo ya está cargado, así como el procesador `nlp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inicia al `matcher` con el vocabulario, `nlp.vocab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `matcher.add()` permite agregar un patrón. El primer argumento es un identificador único para el patrón, el segundo argumento es una función opcional para procesar el resultado, el tercer argumento es el patrón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{'TEXT': 'iPhone'}, {'TEXT': 'X'}]\n",
    "matcher.add('IPHONE_PATTERN', None, pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para buscar coincidencias en el texto con el patrón, llamamos al `matcher` en cualquier documento. Esto devuelve las coincidencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Fecha de lanzamiento del nuevo iPhone X filtrada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando usas el `Matcher` en un `Doc`, revuelve una lista de `tuple`s. Cada `tuple` consiste de tres valores: el id de la coincidencia y los índices inicial y final del `span`. Esto significa que podemos iterar sobre las coincidencias y crear un objeto `Span`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente es un ejemplo de un patrón más complejo usando atributos léxicos.\n",
    "\n",
    "Estamos buscando cinco tokens:\n",
    "1. un token que consista sólo de dígitos,\n",
    "2. tres tokens en mayúscula o minúscula para \"fifa\", \"world\", \"cup\",\n",
    "3. un token que consista en puntuación.\n",
    "\n",
    "Este token coincide con \"2018 Fifa World Cup\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa_pattern = [\n",
    "    {'IS_DIGIT': True},\n",
    "    {'LOWER': 'fifa'},\n",
    "    {'LOWER': 'world'},\n",
    "    {'LOWER': 'cup'},\n",
    "    {'IS_PUNCT': True}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('2018 FIFA World Cup: ¡Francia triunfó!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('FIFA_PATTERN', None, fifa_pattern)\n",
    "fifa_matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 FIFA World Cup:\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in fifa_matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, buscamos dos tokens:\n",
    "1. un sustantivo\n",
    "2. seguido de un verbo con el lemma \"amar\".\n",
    "\n",
    "Este token hace coincidencia con \"amo gatos\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "amor_pattern = [\n",
    "    {'LEMMA': 'amar', 'POS': 'VERB'},\n",
    "    {'POS': 'NOUN'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Amaba perros pero ahora amo gatos más.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('amor_pattern', None, amor_pattern)\n",
    "amor_matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amo gatos\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in amor_matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operadores y cuantificadores te permiten definir qué tan frecuente se debe buscar coincidencias con un token. Pueden agregarse con el `key` `OP`. Aquí el operador `?` hace el token `determiner` opcional, de modo que hará coincidencia con el token con el lemma \"comprar\", un artículo opcional y un sustantivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprar_pattern = [\n",
    "    {'LEMMA': 'comprar'},\n",
    "    {'POS': 'DET', 'OP': '?'}, #opcional\n",
    "    {'POS': 'NOUN'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Me compré un teléfono. Ahora estoy comprando aplicaciones.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('comprar_pattern', None, comprar_pattern)\n",
    "comprar_matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compré un teléfono\n",
      "comprando aplicaciones\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in comprar_matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operadores y cuantificadores\n",
    "\n",
    "| Ejemplo | Descripción |\n",
    "|---|---|\n",
    "| `{'OP': '!'}` | Negación: coincide 0 veces |\n",
    "| `{'OP': '?'}` | Opcional: coincide una o más veces |\n",
    "| `{'OP': '+'}` | Coincide 1 o más veces |\n",
    "| `{'OP': '*'}` | Coincide 0 o más veces |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
